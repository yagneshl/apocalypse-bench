# feat: Next.js results dashboard (shadcn + bar charts)

## Overview

Add a local Next.js dashboard to browse `apocalypse-bench` run results and visualize key metrics with shadcn/ui styling and bar charts.

Primary data source is `runs/<runId>/summary.json`; SQLite (`runs/apocbench.sqlite`) and `runs/<runId>/report.html` are optional deep links/drilldowns.

## Goals

- Quickly answer: “Which model did better, where, and why?”
- Make it easy to browse recent runs stored in-repo under `runs/`.
- Provide a small set of high-signal bar charts + simple filters.

## Non-goals (MVP)

- Real-time updates / live tailing of in-progress runs.
- Cross-run trend analytics (time series, regression, leaderboards).
- Editing datasets or re-running benchmarks from the dashboard.
- Complex drilldown UIs over per-question rows (SQLite is post-MVP unless needed).

## Current repo context (data + reports)

### Run artifacts

- SQLite database: `runs/apocbench.sqlite`
  - Used by existing HTML report generator; queried via `src/storage/sqlite/queries.ts` (`listRunModelResults`).
- Per-run folder: `runs/<runId>/`
  - `summary.json` written by runner/report flow.
  - `report.html` generated by `src/reports/html/renderHtml.ts`.

### Relevant codepaths

- Runner output paths: `src/core/runner/orchestrator.ts` and TUI `src/ui/screens/SummaryScreen.tsx`.
- CLI report generation: `src/cli/index.tsx` (writes `runs/<runId>/{summary.json,report.html}`).
- HTML report renderer: `src/reports/html/renderHtml.ts`.

## Proposed UX

### Information architecture

- `/runs` — runs list
  - list all `runs/<runId>/` folders (ignore non-directories)
  - show: `runId`, `createdAt` (from summary), dataset name, judge model, model count
  - click-through to details
- `/runs/[runId]` — run detail
  - KPI cards (top-line)
  - Bar charts (at least 2)
  - Tables (lightweight)
  - “Open report” link if `report.html` exists

### MVP charts (bar charts)

Use the already-produced `summary.json` breakdown arrays.

For a selected run + selected model:

1) **Score mean by category** (bar)
   - x: `category`
   - y: `overallScoreMean`

2) **Auto-fail rate by difficulty** (bar)
   - x: `difficulty`
   - y: `autoFailRate`

Optional if present in summary:

- **Failures by category** (bar)
  - y: `failures`

### MVP filters

- Run selection: from `/runs`
- Model selector: dropdown over `summary.models[].modelId`
- Sorting: top-N categories (e.g. 20) vs all, with “show all” toggle

### Empty/error states

- No runs found in `runs/` → empty state with guidance.
- Missing/invalid `summary.json` → error banner + still show “Open report” if present.
- Missing `report.html` → disable the button with tooltip.

## Technical approach

### Next.js setup

Create a Next.js app in-repo (new top-level folder, e.g. `dashboard/`) using the provided shadcn preset command:

```bash
pnpm dlx shadcn@latest create --preset https://ui.shadcn.com/init?base=base&style=lyra&baseColor=stone&theme=cyan&iconLibrary=phosphor&font=raleway&menuAccent=bold&menuColor=default&radius=none&template=next --template next
```

Notes:

- Use App Router.
- Keep file/SQLite reads server-side.

### Data access strategy

MVP reads only from the filesystem:

- `runs/<runId>/summary.json` (required)
- `runs/<runId>/report.html` (optional link)

Implementation pattern:

- Server Components read/parse JSON and compute chart series.
- Client Components render charts (Recharts via shadcn/ui chart) and basic interactivity.

### Schema handling

`summary.json` has a stable shape for:

- `runId`, `createdAt`, `datasetPath`, `judge`, `models[]`
- per-model: `overallScoreMean`, `autoFailRate`, `latencyMs`, `categoryBreakdown[]`, `difficultyBreakdown[]`

Treat parsing as defensive:

- If required fields missing, show a recoverable error.
- If some breakdown fields missing, omit the related chart.

### SQLite (post-MVP)

Optional enhancement:

- Add a “Details” tab that queries `runs/apocbench.sqlite` on the server for a run/model and renders a paginated table.

This depends on the SQLite schema stability and may require indexes for good performance.

## Security considerations

- Do not embed `report.html` in an iframe by default; link to it (new tab) to avoid executing arbitrary scripts inside the dashboard origin.
- Ensure filesystem paths are not user-controlled beyond selecting a `runId` from discovered directories (no path traversal).
- Keep `runs/apocbench.sqlite` access server-only.

## Performance considerations

- Runs list should avoid heavy work: read only minimal metadata (e.g. parse `summary.json` for each run). Consider limiting to latest N by default.
- Charts should use pre-aggregated breakdowns from `summary.json` (no per-row processing).

## Acceptance criteria

- [ ] `/runs` lists run folders under `runs/` and renders an empty state when none exist.
- [ ] Clicking a run navigates to `/runs/[runId]` and renders KPI cards + charts using `runs/<runId>/summary.json`.
- [ ] The run detail page never reads files from the client; all file access occurs on the server.
- [ ] Model selector switches chart data between `summary.models[]` entries.
- [ ] Missing/invalid `summary.json` shows a clear error banner and still offers a report link if `runs/<runId>/report.html` exists.
- [ ] At least two bar charts render for a valid run: score mean by category and auto-fail rate by difficulty.
- [ ] “Open report” link works when present and is disabled when absent.

## Implementation plan (MVP)

### Phase 0 — Confirm scope + wiring

- Define the dashboard folder name (recommend: `dashboard/`).
- Runs path configuration:
  - Use `RUNS_DIR` env var.
  - Fallback: `path.join(process.cwd(), "../runs")`.
  - Treat `RUNS_DIR` as an absolute path.
  - Reject any `runId` that is not an exact directory name discovered under `RUNS_DIR` (no path traversal).
- Workspace integration (pnpm):
  - If `pnpm-workspace.yaml` exists, add `dashboard/` so you can run `pnpm --filter dashboard dev` from repo root.
  - If it does not exist, create `pnpm-workspace.yaml` with `packages: ["dashboard"]`.

### Phase 1 — App scaffold (shadcn preset)

- Run the provided `pnpm dlx shadcn@latest create ...` command to scaffold Next.js + shadcn.
- Ensure the scaffold uses App Router and shadcn/ui is configured.

### Phase 2 — Server data utilities

- Implement run discovery:
  - Enumerate directories under `../runs`.
  - For each, try to parse `summary.json` to extract minimal metadata.
- Implement run detail loader:
  - Parse `summary.json` for a given run.
  - Derive chart series from `categoryBreakdown` and `difficultyBreakdown`.

### Phase 3 — UI routes + components

- `/runs` page:
  - table/list in shadcn cards
- `/runs/[runId]` page:
  - KPI cards
  - model selector
  - 2 bar charts using shadcn Chart (Recharts)
  - report link button

### Phase 4 — Validation

- Add minimal unit tests for the summary parser and chart series derivation (if the dashboard section has a test runner), or ensure the dashboard can start in dev and render a known run.

## References

- Next.js data fetching patterns (App Router): https://nextjs.org/docs/14/app/building-your-application/data-fetching/patterns
- shadcn/ui CLI: https://ui.shadcn.com/docs/cli
- shadcn/ui Chart (Recharts): https://ui.shadcn.com/docs/components/chart
