run:
  name: "default"
  datasetPath: "./data/question_bank_v7.jsonl"
  outDir: "./runs"
  resume: true
  questionLimit: null
  categories: null
  maxBudgetUsd: null
  concurrency:
    candidate: 3
    judge: 5

judge:
  router: "openrouter"
  model: "google/gemini-3-flash-preview"
  provider: "google-ai-studio"
  temperature: null
  maxTokens: 16000
  structured: true

routers:
  ollama:
    baseUrl: "http://localhost:11434/v1"
    apiKeyEnv: null
    default:
      temperature: 0.2
      maxTokens: 800
      timeoutMs: 120000

  openrouter:
    baseUrl: "https://openrouter.ai/api/v1"
    apiKeyEnv: "OPENROUTER_API_KEY"
    headers:
      HTTP-Referer: "https://github.com/yourname/apocalypse-bench"
      X-Title: "apocalypse-bench"
    default:
      temperature: 0.2
      maxTokens: 800
      timeoutMs: 120000

models:
  - id: "openrouter:liquid/lfm-2.2-6b"
    router: "openrouter"
    model: "liquid/lfm-2.2-6b"
    provider: "liquid"
models:
  - id: "openrouter:liquid/lfm2-8b-a1b"
    router: "openrouter"
    model: "liquid/lfm2-8b-a1b"
    provider: "liquid"
models:
  - id: "openrouter:openai/gpt-oss-20b"
    router: "openrouter"
    model: "openai/gpt-oss-20b"
    provider: "groq"
models:
  - id: "openrouter:nvidia/nemotron-nano-9b-v2"
    router: "openrouter"
    model: "nvidia/nemotron-nano-9b-v2"
    provider: "deepinfra/bf16"
models:
  - id: "openrouter:meta-llama/llama-3.1-8b-instruct"
    router: "openrouter"
    model: "meta-llama/llama-3.1-8b-instruct"
    provider: "groq"
# models:
#   - id: "openrouter:google/gemini-3-flash-preview"
#     router: "openrouter"
#     model: "google/gemini-3-flash-preview"
#     provider: "google-vertex"
# models:
#   - id: "openrouter:kimi-k2"
#     router: "openrouter"
#     model: "moonshotai/kimi-k2-0905"
#     provider: "groq"
